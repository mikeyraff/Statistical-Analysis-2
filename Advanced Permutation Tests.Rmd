---
title: "Homework 2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T,eval=T,message=F,warning=F,fig.align='center')
```


## Problem 1 <small>(10pts)</small>

According to a recent U.N. report, the warmest eight years on record have all been since 2015. That is, the years 2015, 2016, 2017, 2018, 2019, 2020, 2021, and 2022 were the eight warmest years (though not necessarily in that order) since record-keeping began circa 1850. Let's simplify things a bit, and suppose that records exist just for the past 12 years, with the first recorded temperature in 2011 and with 2022 being the last year.

Suppose the average temperatures for the past 12 years were random with no trend. Then we would expect that any of the 12 years on record is equally likely to be the hottest on record, any of the remaining 11 years on record is equally likely to be the second hottest on record, etc. Use Monte Carlo to estimate the probability that, under this model in which all temperature orderings are equally likely, the eight warmest years on record all occurred in the last eight years 2015-2022.

*Hints*:

 - A completely equivalent question asks, if we order the numbers 1 to 10 completely at random, what is the probability that the numbers $\{1, 2, 3, 4, 5, 6, 7 \}$ appear in the first seven entries in the ordering?
Bear in mind that this *does not* require that 1 appear first in the ordering, 2 second, etc., only that the first seven numbers appear in the first seven "entries" of our ordering.
 - If `n` is a positive integer, `sample( n, n, replace=FALSE )` will give a random ordering of the numbers `1` through `n`  - Suppose you have an R vector `v` of length `n`, consisting of each the integers 1 through `n`, in some order. What is a good way to check that the numbers 1,2,3,4,5,6,7 all appear in the first seven elements of `v`? One (rather naive) approach would be to just check, for each $i \in \{ 1,2,3,4,5,6,7 \}$, that one of the first seven elements of `v` is equal to $i$, but this would be rather slow. Convince yourself that an equivalent approach is to check if the first seven elements of `v` sum to `sum(1:7)`.

Use at least 10,000 Monte Carlo iterates to produce your estimate. If you take the hints above into account correctly, you should be able to run this many Monte Carlo iterates with little or no trouble. Otherwise, your experiment may require a few minutes to run. If things are taking an especially long time, feel free to reduce that 10,000 figure down to 1000.

```{r}
num_iterations = 10000
num_years = 12
hottest_years = 8
count = 0
for (i in 1:num_iterations) {
  temps = runif(num_years)
  hottest = order(temps, decreasing = TRUE)[1:hottest_years]
  if (all(hottest > num_years - hottest_years)) {
    count = count + 1
  }
}
prob = count / num_iterations * 100
prob

```


## Problem 2 <small>(10pts)</small>

Let the following vector represent a deck of cards (for simplicity, we're ignoring suits (symbols) for now and only focusing on the ranks (numbers)).

```{r}
deck = rep(1:13,each=4)
deck
```

Suppose you draw 5 cards. Using MC, estimate the probability of the following outcomes. Try to run as many iterations as you can comfortably run so you can get a better estimate of each. If you have run as many iterations as you can and you still do not observe a single occurrence of an event, you may state the probability as less than 1/M, where M is the number of iterations you used.

1. A hand with all 5 cards having different ranks
2. A hand with no cards that are 10 or higher
3. A hand with two pairs (e.g. 3,3,7,7,9)
4. A hand with a pair and a triple (e.g. 5,5,5,2,2)
5. A hand with a four of a kind (e.g. 8,8,8,8,10)

```{r}
num_iterations = 10000 

# 1. A hand with all 5 cards having different ranks
count_1 = 0
for (i in 1:num_iterations) {
  hand = sample(deck, 5)
  if (length(unique(hand)) == 5) {
    count_1 = count_1 + 1
  }
}
prob_1 = count_1 / num_iterations * 100
prob_1

# 2. A hand with no cards that are 10 or higher
count_2 = 0
for (i in 1:num_iterations) {
  hand = sample(deck, 5)
  if (max(hand) < 10) {
    count_2 = count_2 + 1
  }
}
prob_2 = count_2 / num_iterations * 100
prob_2

# 3. A hand with two pairs (e.g. 3,3,7,7,9)
count_3 <- 0
for (i in 1:num_iterations) {
  hand = sample(deck, 5)
  if (length(unique(hand)) == 3 && max(table(hand)) == 2) {
    count_3 = count_3 + 1
  }
}
prob_3 = count_3 / num_iterations * 100
prob_3

# 4. A hand with a pair and a triple (e.g. 5,5,5,2,2)
count_4 = 0
for (i in 1:num_iterations) {
  hand = sample(deck, 5)
  if (length(unique(hand)) == 2 && max(table(hand)) == 3) {
    count_4 = count_4 + 1
  }
}
prob_4 = count_4 / num_iterations * 100
prob_4

# 5. A hand with a four of a kind (e.g. 8,8,8,8,10)
count_5 = 0
for (i in 1:num_iterations) {
  hand = sample(deck, 5)
  if (max(table(hand)) == 4) {
    count_5 = count_5 + 1
  }
}
prob_5 = count_5 / num_iterations * 100
prob_5
```

## Problem 3: Permutation testing <small>(10pts)</small>

Below are data arising from a (fictionalized) data source: the number of defects per day on an assembly line before and after installation of a new torque converter (this is a totally fictional "part" of an assembly line--just treat these as "control" and "treatment" groups, respectively).

```{r}
before = c(4,5,6,3,6,3,4,5,5,3,4,6,4,6,3,4,2,2,0,7,5,8,4,5,1,4,4,8,2,3)
after  = c(3,2,4,3,7,5,5,2,2,4,5,2,2,6,1,5,6,3,2,3,7,3,4,5,4,2,2,6,7,8)
```

a) Use a permutation test to assess the claim that installation of the new part changed the prevalence of defects. That is, test the null hypothesis that the distribution of defects is the same before and after installation of the new part. Produce a p-value and interpret the results of your test in context.

```{r}
t_stat = mean(after) - mean(before)
data = c(before, after)
permutations = 10000
perm_stats = numeric(permutations)

for (i in 1:permutations) {
  sample_data = sample(data)
  group1 = sample_data[1:length(before)]
  group2 = sample_data[(length(before) + 1):length(sample_data)]

  perm_stats[i] = mean(group2) - mean(group1)
}

# Two-Sided Test p-value
p_value_2sided = mean(abs(perm_stats) >= abs(t_stat))
p_value_2sided

# One-Sided Test p-value
p_value_1sided = mean(abs(perm_stats) <= abs(t_stat))
p_value_1sided
```

b) Explain, briefly, what you did above and why. Imagine that you are trying to explain to someone who isn't well versed in statistics what exactly you are doing in a permutation test. Explain your conclusion based on your test above. Three to five sentences should be plenty, but you are free to write as much or as little as you think is necessary to clearly explain your findings.

In a permutation test we randomly sample data and split it into two groups many times over, and each time we compute a test statistic. Then, we compare the observed test statistic to the distribution of test statistics generated by the permutations. Depending on the value of the observed test statistic then we can conclude if we reject or fail to reject the null hypothesis that the distribution of is the same before and after the permutation process. In the context of the test, the p-value acts as your risk for rejecting the null of a hypothesis test when the null is actually true. For my two-sided test, the p-value of about 0.72 is greater than 0.05, which indicates that we fail to reject the null hypothesis.

## Problem 4: Memes <small>(10pts)</small>

The following question comes from Karl Rohe, who developed the very first version of this class. This question has been reproduced in nearly the exact original (very amusing) wording.

> **Memes, part 1** (Please forgive me. I drank too much coffee before writing this question.)
> 
> In class thus far, there have been 416 comments posted in the bbcollaborate chat during class. An expert panel has judged 47 of these comments to be memes. The big-bad-deans say that they are concerned "if there is evidence that more than 10% of comments are memes." So, this looks like bad news, 47/416>10%.
> 
> Karl pleads with the deans: "Please, oh please, you big-bad-deans... Memeing is totally random." (I don't actually know what this notion of "random" means, but please just run with it for this question.) Then, along comes you, a trusty and dedicated 340 student. You say that "because we have only observed 416 comments, we don't really know what the 'true proportion' of memes."
> 
> 4a: What would be a good distribution for the number of memes?
> 
> 4b: Using your distribution from 4a, test the null hypothesis that the 'true proportion' is actually 10%. It's all up to you now... report the p-value.

Hints:

- For 4a, there should be a (hopefully) fairly intuitive choice of random variable that makes sense here. Look at your list of random variables and ask yourself which of these makes the most sense.
- For 4b, you can use the built-in function in R to simulate observations according to your null. Remember that you **always simulate *assuming* the null hypothesis**. Make sure your choice of the necessary parameter(s) reflects this assumption.

```{r}
# 4a
binom.test(47, 416, p=0.1, alternative = "greater")
```
A good distribution for the number of memes out of 416 comments would be a binomial distribution. There are possible outcomes of each event, which in this case is whether or not a comment is a meme or not.

```{r}
# 4b
n = 416
p = 0.1
x = 47
p_value = 1 - pbinom(x - 1, n, p)
p_value
```

## Problem 5: Testing coin flips <small>(10 pts)</small>

In the six sequences below, only one of them is actually **randomly generated from independent flips of a fair coin**. Use a combination of everything you know (common sense, Monte Carlo, hypothesis testing, etc.) to identify which is actually random and explain your reasoning.

(For full points, conduct a formal test and report a p-value for each sequence. You may use a combination of multiple tests to arrive at your answer. If you cannot compute a p-value for each sequence, you can still earn a significant amount of partial credit by carefully explaining your reasoning and response as best as you can.)

My advice is **be creative** with the test statistics you come up with to eliminate each sequence! Think of some way of summarizing a sequence of flips that might be useful for comparing against a simulated sequence of random flips. After you come up with an idea for a statistic, remember to run it on many MC generated completely random flips to produce a distribution under the null, which you can then compare with your data to get a p-value. Also, be careful of now you define "more extreme" than the data.

(2 bonus points available if you can find a single test that is powerful enough to reject all the fake sequences together in one step. Yes, at least one such possible test exists.)

```{r}
flips1 = "HTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHT"

flips2 = "HHHTHTTTHHTHHTHHHTTTTHTHTHHTTHTHHHTHHTHTTTHTHHHTHTTTHTHTHHTHTHTTHTHHTHTHTTTHTHHHTHTHTTHTHTHHTHTHTHHHTHTTTHTHHTHTHTHHTTTHTHHTHHTTTTHTHTHHHTHTTHTHHTHTHTTHTHHTHTHHHTHHHTHTTTHTTHTTTHTHHHTHTHTTHTHHTHHTHTTT"

flips3 = "HHTHTHTTTHTHHHTHHTTTHTHHTHTTTHTHTHHTHTHTTHTHHHHHHTTTHTHTHHTHTTTHTHHTHTHTTTHTHHHTTHTTTHTHTHHHHTHTTHHTTTTTHTHHHTHTHTTTTTHHHTHHTHHTHHHTTTTHTHTHHHTHHTTTTTHTHHHTHTHTHTTTHTHHHTHTHTHTTHTHHTHTHTHTTTTHTHHHTHTH"

flips4 = "HTHHHHHHHTHTTHHTTHHHTHTHTTTHHTHHHTHHTTHTTTTTTTTTHTHHTTTTTHTHTHTHHTTHTTHTTTTTHHHTHTTTHTHTHHHTHTTTTHTHTHHTTHTHTTHHTHTHHHHTHTTHHTTHTTHTTHTHHHHHHTTTTTTHHHTTHTHHHHTTTHTTHHHTTHTHHTTTHHTHHTTTHTHHTHHHTHHTTHHH"

flips5 = "HHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTT"

flips6 = "TTHTTTHTTTTTTTHTHTHTHTTHTTHTHHTHHTTTHHTHTTTHTHHTHHHTHTTHHTHHTTHTHTTTTHTHTTTHHTTTTTTTTHTHHTTHTTTTTTHTHTHTHTTTHTTHHTTHTTTHHTTTHTTHTTTTHTTTTHHTTTHTHTHHHTTTTTTHTHHTTTTTTTTTTTTHHHTTTHHHTTTHTTTHTHTTHTTTTTHT"

# you can use the function below to split the above sequences in vectors of flips
split = function(str) strsplit(str, split="")[[1]]
split(flips1)
```

```{r}
# Chi Squared Test
coin_flip_test = function(flips) {
  flips_vec = split(flips)
  n = length(flips_vec)
  obs_freqs = table(flips_vec)
  exp_freqs = rep(n/2, 2)
  chi_sq = sum((obs_freqs - exp_freqs)^2 / exp_freqs)
  p_value = 1 - pchisq(chi_sq, 1)
  return(p_value)
}
p_values = c(coin_flip_test(flips1), coin_flip_test(flips2), coin_flip_test(flips3),
             coin_flip_test(flips4), coin_flip_test(flips5), coin_flip_test(flips6))
p_values
```

```{r}
if(!"runner" %in% rownames(installed.packages())) install.packages("runner")
# define function for tabulating consecutive pairs
tableOfPairs = function(vec){
  return(table(runner::runner(vec,k=2,f=paste,collapse="")[-1]))
}
# test function for correct output
tableOfPairs(strsplit("HHTTHTTH",split="")[[1]])

ratioFromTable = function(tb){
  return(setNames((tb["HH"]/tb["TT"])/(tb["HT"]/tb["TH"]),"R"))
}

# Flip 1
flips1_vec = split(flips1)
tableOfPairs(flips1_vec)
ratioFromTable(tableOfPairs(flips1_vec))
# set number of reps to use
N = 10000
# create another vector to save results in
mc.flips1 = rep(NA,N)
# for each rep, randomize sequence and find ratio R
for(i in 1:N){
    mc.flips1[i] = ratioFromTable(tableOfPairs(sample(flips1_vec)))}
hist(mc.flips1)

# Flip 2
flips2_vec = split(flips2)
tableOfPairs(flips2_vec)
ratioFromTable(tableOfPairs(flips2_vec))
# set number of reps to use
N = 10000
# create another vector to save results in
mc.flips2 = rep(NA,N)
# for each rep, randomize sequence and find ratio R
for(i in 1:N){
    mc.flips2[i] = ratioFromTable(tableOfPairs(sample(flips2_vec)))}
hist(mc.flips2)

# Flip 3
flips3_vec = split(flips3)
tableOfPairs(flips3_vec)
ratioFromTable(tableOfPairs(flips3_vec))
# set number of reps to use
N = 10000
# create another vector to save results in
mc.flips3 = rep(NA,N)
# for each rep, randomize sequence and find ratio R
for(i in 1:N){
    mc.flips3[i] = ratioFromTable(tableOfPairs(sample(flips3_vec)))}
hist(mc.flips3)

# Flip 4
flips4_vec = split(flips4)
tableOfPairs(flips4_vec)
ratioFromTable(tableOfPairs(flips4_vec))
# set number of reps to use
N = 10000
# create another vector to save results in
mc.flips4 = rep(NA,N)
# for each rep, randomize sequence and find ratio R
for(i in 1:N){
    mc.flips4[i] = ratioFromTable(tableOfPairs(sample(flips4_vec)))}
hist(mc.flips4)

# Flip 5
flips5_vec = split(flips5)
tableOfPairs(flips5_vec)
ratioFromTable(tableOfPairs(flips5_vec))
# set number of reps to use
N = 10000
# create another vector to save results in
mc.flips5 = rep(NA,N)
# for each rep, randomize sequence and find ratio R
for(i in 1:N){
    mc.flips5[i] = ratioFromTable(tableOfPairs(sample(flips5_vec)))}
hist(mc.flips5)

# Flip 6
flips6_vec = split(flips6)
tableOfPairs(flips6_vec)
ratioFromTable(tableOfPairs(flips6_vec))
# set number of reps to use
N = 10000
# create another vector to save results in
mc.flips6 = rep(NA,N)
# for each rep, randomize sequence and find ratio R
for(i in 1:N){
    mc.flips6[i] = ratioFromTable(tableOfPairs(sample(flips6_vec)))}
hist(mc.flips6)
```

While conducting a hypothesis test: H0 = the trial of coin flips is not randomly generated from independent flips and the H1 = the trial of coin flips are randomly generated. With the null and alternative hypothesis set, we can now use our generated p-values through the chi-squared testing function. I chose a chi-squared test because it is accurate at determine if a difference between observed values and expected values is due to chance or varaibles of interest. After running a test for each of the six flip sequences, the only p-value lower than the assumed significance level of 0.05 was for the sixth sequence. Therefore, for flip six we reject the null making it the randomly generated sequence. The others all have high p-values closer to 1, which is much higher than the significance level, so we would fail to reject the null for the other five flips. To further prove that the sixth sequence is te randomly generated one, I conducted a test detecting patterns in each sequence of coin flips to see if the occurrance of repeated outcomes ie. HH or TT was common among the group. I then took each sequence and created samples with multiple iterations to get an accurate idea of what each sequence of flips would look. I used functions to help me do this. I used histograms to visualize where most of the iterations ended up, and the graph for the sixth sequence demonstrated the most random possibilities compared to the previous 5 whose graphs show very little evidence of random independent trials.