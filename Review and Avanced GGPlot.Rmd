---
title: "Homework 1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T,eval=T,message=F,warning=F,fig.align='center')
library(tidyverse)
library(ggplot2)
```


## Problem 1 <small>(2pts each, 8pts total)</small>

Here are a few probability exercises to get you warmed up.

a. Find the variance of a fair d20 die (i.e. 20-sided die with numbers 1,2,...,20). You may use R if you like.
b. Suppose you have an uneven 6-sided die where the numbers 1-5 are equally likely to occur, and the expected value of the entire die is 4. What is the probability of getting a 6?
   (Hint: Let $x$ represent the probability of getting a 6, and represent the probability of the other numbers algebraically. Then derive an expression for the expected value, let it equal 4, and solve. You can go back and check your work by plugging the result back into your original expressions and verify it works with R.)
c. Give **two examples** of pairs of events that are mutually exclusive and explain why for each.
d. Give **two examples** of pairs of events that are independent and explain why for each.

```{r}
# 1a
mu = (20 + 1)/2
variance = sum((1:20 - mu)^2)/20
variance
```

```{r}
# 1b
# Calculated on paper, but wanted to show that with the answer x = 1/3, the probability is 4 with the following equation:
x = 1/3
prob_6 = (1-x)/5*1 + (1-x)/5*2 + (1-x)/5*3 + (1-x)/5*4 + (1-x)/5*5 + x*6
prob_6
```

```{r}
x
```

# 1c
Example 1: Rolling a 6 on a fair 6-sided die and rolling a 5 on the same die. Only one of these two events can occur at a time because there are no duplicates on a fair die.

Example 2: Drawing a spade from a deck of cards and drawing a club from the same deck. Only one of these events can occur at a time because a card can only be in place at a time.

# 1d
Example 1: Tossing a fair coin and rawing a card from a deck of cards. These two events are independent because the outcome of one does not affect the outcome of the other.

Example 2: Rolling a 6-sided die and flipping a fair coin. These two events are independent because the outcome of one does not affect the outcome of the other.

## Problem 2 <small>(2pts each, 12pts total)</small>

For each of the following scenarios, decide what random variable may be appropriate to use as a model, and explain your reasoning as well as any assumptions you make.

a. The number of patients in an experimental drug trial that respond to treatment.
b. The number of Teslas you see on your way to school in the morning.
c. What the second hand reads on the clock when you wake up from a long nap (approximately).
d. How many people you need to swipe right on Tinder before you get a match.
e. The number of shoes of each size in a shoe store (approximately).
f. Whether the Eagles win the Superbowl this year.

# 2a
A binomial random variable with the assumptions that each patient is an independent trial, and the probability of a patient responding is constant.

# 2b 
A Poisson random variable with the assumptions that the average number of Teslas you see on your way to school is constant, and the number of Teslas you see is proportional to the length of your drive to school.

# 2c
A continuous uniform random variable with the only assumption that the second hand can take any value between 0 and 60 with equal intervals.

# 2d
A geometric random variable with the only assumption that the number of swipes you need to get a match is proportional to the inverse of the probability of getting a match on Tinder.

# 2e
A discrete random variable with the assumptions that the sizes of the shoes in the store are independent, and the number of shoes of each size is proportional to the number of shoes in the store.

# 2f
A Bernoulli random variable with the assumption that there are only two possible outcomes being either the Eagles win or lose.

## Problem 3 <small>(2pts each, 10pts total)</small>

For this next problem, we're going to empirically demonstrate the law of large numbers by simulating $N$ observations of a random variable, and show the convergence of the sample mean to the theoretical mean. Consider a poisson variable $X$ with $\lambda=13$. It should hopefully be clear from the definition of the poisson that $E(X)=\lambda=13$.

a. Start by creating a data frame with 2 columns: a column named `n` that goes from 1, 2, ..., up to 1000; and a second column named `x` which is just 1000 repeated observations of a poisson random variable with `lambda=13`.
b. Next, create a third column named `xbar` that computes the "mean-thus-far" up to each row. E.g. if the first 3 values of `x` are 3, 1, 8, then the first 3 values of `xbar` should be 3, 2, 4, since 3=3, (3+1)/2=2, and (3+1+8)/3=4.
   (Hint: use the `cumsum()` function to take the cumulative sum of the `x` column, then divide by the number of observations so far)
c. Make a line plot showing xbar vs n. Add a red line at the theoretical mean. Comment on what you observe in the plot. Is this what you were expecting? (Don't forget to add proper labels/titles).
d. Now, increase the number of simulations to 100,000 and remake the plot, this time with a log-scale x-axis to better show the rate of convergence across the entire axis. Comment again on the output. Explain if this does or does not empirically agree with the law of large numbers.
e. Repeat the above steps with a **different** random variable. You can copy your entire code chunk so far and just make the necessary modifications. Comment on this output too and whether or not it also agrees with your expectations. Make sure you CLEARLY define what the random variable you're using and clearly state what the expected value is (you may look this up on the internet if it's a new random variable we covered this week that we did not give the expectation formula for in class).
```{r}
# 3a
n = seq(1, 1000)
x = rpois(1000, 13)
df = data.frame(n, x)

# 3b
df$xbar = cumsum(df$x)/df$n

# 3c
ggplot(df, aes(x=n, y=xbar)) + geom_line() + geom_hline(yintercept = 13, color = 'red') + xlab("Values from 1 to 1000 (n)") + ylab("Mean") + ggtitle("Sample Mean Compared to Theoretical Mean")
```
For the grpah in part c, the sample mean versus the number of observations would show the convergence of the sample mean to the theoretical mean as the number of observations increases, and the theoretical mean is represented with the red line. The result is what I expected because it shows convergence between the sample mean and expected value.

```{r}
# 3d
n = seq(1, 100000)
x = rpois(100000, 13)
df = data.frame(n, x)
df$xbar = cumsum(df$x)/df$n
ggplot(df, aes(x=n, y=xbar)) + geom_line() + geom_hline(yintercept = 13, color = 'red') + xlab("Values from 1 to 100000 (n)") + ylab("Mean") + ggtitle("Sample Mean Compared to Theoretical Mean")
```
For graph d, it would be similar to the one is part c except for the scale of the x-axis, which is a better way of showing the rate of convergence across the entire axis, and as the number of observations increases, the sample mean should converge more and more towards the theoretical mean. This graph also shows the empircial demonstration of the law of large numbers, which supports the idea that the sample mean of a large number independent and identically distributed random variables converges to the expected value.

```{r}
# 3e
n = seq(1, 100000)
mu = 100
sigma = 10
x = rnorm(100000, mu, sigma)
df = data.frame(n, x)
df$xbar = cumsum(df$x)/df$n
ggplot(df, aes(x=n, y=xbar)) + geom_line() + geom_hline(yintercept = mu, color = 'red') + xlab("Values from 1 to 100000 (n)") + ylab("Sample Mean") + ggtitle("Law of Large Numbers for a Normal(100,10) Model")
```
Finally, in part e, the graph shows the empirical demonstration of the law of large numbers for a different random variable of my choice. The graph shows the convergence of the sample mean the expected value as the number of observations increases.

<br/><br/>
***The last 2 problems are intended to be done after we begin the Monte Carlo lectures, but you are welcome to get a head start on them if you feel motivated to do so.***
<br/><br/>



## Problem 4: Generalized [birthday problem](https://en.wikipedia.org/wiki/Birthday_problem) <small>(12pts)</small>

The birthday problem asks for the probability that in a group of $n$ people, **at least 2 people** will share the same birthday. This is a standard question in introductory probability. In this problem, we will generalize the birthday problem to a much more difficult question and then solve it using a Monte Carlo approach.

__Question:__ in $n$ people, what is the probability that at least $k$ people have the same birthday?

Write a function `birthday(n, k, m)` that takes 3 arguments:

 - $n$ is the number of people in your sample
    - for example, if `n=50` is used, we are asking "in 50 people, what is the probability that..."
 - $k$ is minimum number of people that you asking for the probability of sharing a birthday
    - for example if `k=4` is used, we asking "...what is the probability that at least 4 people share the same birthday?
 - $m$ is the number of replicates in your simulation (default 1000)
    - for example, if `m=1000` is used, your function should run 1000 replicates

`birthday(n, k, m)` should return a Monte Carlo estimate, based on `m` Monte Carlo replicates, of the probability that among `n` people, at least `k` of them have the same birthday.

__Notes:__

 - You may assume there are 365 possible dates (no leap years)
 - You may assume birthdays are uniformly distributed across the calendar
    - this is actually not true; see [this](https://www.panix.com/~murphy/bday.html), or [this](https://fivethirtyeight.com/features/lots-of-parents-dont-want-their-kids-to-be-born-on-leap-day/), but we're going to make the simplifying assumption.
 - You may assume the people are sampled [i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables).

__Hints:__

1. There's no need to use actual dates in the simulation process. Numbers can represent dates and are easier to generate and manipulate in `R`. In particular, we recommend using the `sample()` function with the `x`, `size`, and `replace` arguments set appropriately. See the help page `?sample` for details.
2. Given a vector of numbers, you can easily find duplicates by using the `table()` function. This will produce a named vector showing how many of each value there are. For example, running `table(c(1, 3, 5, 5, 7, 9, 9, 9))` will show you there is one 1, one 3, two 5s, one 7, and three 9s.
3. In your function, you will need to use a `for` loop to repeat the simulation `m` times. You will also need a variable outside your `for` loop to keep track of how many replicates satisfy that the number of people with same birthdays $\geq k$.
4. If your function is running correctly, then `birthday(n=23,k=2)`, `birthday(n=87,k=3)` and `birthday(n=188,k=4)` should all be approximately $50\%$.
5. If your function is very slow, make sure you're paying attention to hint 1 and using numbers appropriately to represent dates in a memory efficient way. You may also consider using the [`dqsample` function](https://rdrr.io/cran/dqrng/man/dqsample.html) from the `dqrng` package which is about 2-3 times faster than the normal `sample` function, or the [`Table` function](https://rdrr.io/cran/Rfast/man/Table.html) from the `Rfast` package which is about 4-5 times faster than the normal `table()` function (especially if you set `names=FALSE`).

```{r}
# Reminder: m = 1000 sets the default value of m to be 1000
birthday = function(n, k, m=1000) {
  count = 0
  x = 1:365
  for (i in 1:m){
    birthdays = sample(x, n, replace=TRUE)
    if (any(table(birthdays) >= k)) count = count + 1
  }  
  return((count/m) * 100)
}
```

This class currently has 285 enrolled students (across two sections). Use your function to estimate the approximate probability that at least $5$ students have the same birthdays? Use as many replicates can you can comfortably run on your computer.
```{r}
birthday(n=285, k=5, m=1000)
```


## Problem 5: Simulating a random variable <small>(8pts)</small>

Define a random variable $X$ with density
$$
f_X(t) = \begin{cases}
      2t &\mbox{ if } 0 \le t \le 1 \\
      0 &\mbox{ otherwise. }
      \end{cases}
$$


```{r, fig.width=5.7, fig.height=4}
# here we define a *vectorized* function to evaluate the density of X
pdf_x = function(x) {
  # ifelse is like a function version of an if statement.
  # We use it here to ensure that pdf_x can operate directly on vectors.
  return(ifelse(0<=x & x<=1 , 2*x , 0 ))
}

# showing the PDF in a plot
ggplot() + geom_function(fun=pdf_x, n=10001) + 
  coord_fixed(ratio=.5) + theme_minimal() + 
  xlim(c(-1,2)) + ylim(-1,3) + labs(x="x", y="f(x)")
```

This means that the cumulative distribution function is $$F_X(t)=\int_0^tf_X(u)du=t^2$$
for $0 \le t \le 1$, and $F_X(t) = 1$ for $t \ge 1$.
Write a function `rx(n)` (like `rbinom`) to sample from this random variable, where `n` is the size of the sample to be drawn.
Then, use your function to draw sample of size 1000 and plot a histogram of the output to verify the results make sense.

```{r}
# complete the function
rx = function(n) {
  runif(n, 0, 1)^0.5
}
set.seed(1)
sample = rx(1000)
hist(sample, col = "white", main = "Histogram of the Sample", xlab = "x")
hist(rx(1000))
```