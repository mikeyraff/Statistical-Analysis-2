---
title: "Homework 5"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T,eval=T,message=F,warning=F,fig.align='center')
```

Each part of each question will be 5pts, there are 10 parts, so 50pts total. <br/>


## 1. Interpreting logistic regression <small>15pts</small>

Suppose we collect data for a group of students in a statistics class with independent variables $X_{1}=\text{hours studied}$, $X_{2}=\text{GPA}$, and binary response variable
$$
Y= \begin{cases} 1 &\mbox{ if student received an A} \\
  0 &\mbox{ otherwise. }
  \end{cases}
$$
Suppose that we fit a logistic regression model to the data, predicting $Y$ from $X_1$ and $X_2$ (and an intercept term) and produce estimated coefficients $\hat{\beta}_{0}=-6, \hat{\beta}_{1}=0.05, \hat{\beta}_{2}=1$.

### Part a) Logistic regression and probability

According to our fitted model, what is the probability that a student receives an A if they study for $40$ hours and have a GPA of $3.5$?

```{r}
beta0 = -6
beta1 = 0.05
beta2 = 1
hours_studied = 40
GPA = 3.5
z = beta0 + beta1 * hours_studied + beta2 * GPA
probability_A = 1 / (1 + exp(-z))
probability_A
```

### Part b) Interpreting coefficients
According to our fitted model, an additional hour spent studying is associated with *how much* of an increase in the log odds of receiving an A?

```{r}
beta1
```
The coefficient for the hours studied (Î²1) is 0.05. This means that for each additional hour spent studying, the log odds of receiving an A increase by 0.05.

### Part c) "Inverting" logistic regression probabilities
According to our fitted model, how many hours would the student in Part (a) need to study to have a $50\%$ chance of getting an A in the class?
That is, keeping GPA fixed at $3.5$, how many hours of study are needed so that the probability of an A is $50\%$?
If you aren't up for the math, feel free to find an approximate solution via guess-and-check in R.

***

We need to find X1 (hours_studied) such that P(Y=1) = 0.5. We can use the equation:
0.5 = 1 / (1 + exp(-z)) and solve for X1.

***

```{r}
target_probability = 0.5
desired_hours = -1
for (hours in 1:1000) {
  z = beta0 + beta1 * hours + beta2 * GPA
  probability = 1 / (1 + exp(-z))
  
  if (probability >= target_probability) {
    desired_hours = hours
    break
  }
}
desired_hours
```


<br/>

## 2. `mtcars` one more time <small>10pts</small>

Let's take yet another look at the `mtcars` data set.
Recall that the columns of this data set are:
```{r}
names(mtcars)
```

The `am` column encodes whether a car is automatic (`0`) or manual (`1`).
Let's build a model to predict whether a car is manual or automatic.

### Part a) Fitting/interpreting a model

Fit a logistic regression model to regress `am` against the `drat` and `disp` (and an intercept term).

```{r}
mtcars_logistic = glm(am ~ drat + disp, data = mtcars, family = "binomial")
summary(mtcars_logistic)
```

Which coefficients (if any) are statistically significantly different from zero at the $\alpha=0.05$ level?
Interpret the meaning of the estimated coefficient(s) that is/are statistically significantly different from zero.

***

In the logistic regression, the 'drat' coefficient is statistically significant and positive, indicating that higher rear axle ratios increase the log-odds of a car having a manual transmission. The 'disp' coefficient is not statistically significant, suggesting that engine displacement does not significantly affect the probability of a manual transmission.

***

### Part b) Modifying/assessing the model

Choose one of the statistically significant predictors above and re-fit a model using *only* that variable (and an intercept) to predict `am`.
We'll see how to compare the quality of this model to the one from Part (a) when we talk about cross-validation (CV) in upcoming lectures.
For now, compare the estimated coefficient of this variable in both models.
Is there a sizable difference?

Does anything else notable change about the model?

```{r}
mtcars_logistic_drat = glm(am ~ drat, data = mtcars, family = "binomial")
summary(mtcars_logistic_drat)
```
Comparing the two models, the 'drat' coefficient remains statistically significant and positive, suggesting that higher rear axle ratios increase the log-odds of a car having a manual transmission. The new model has a slightly lower AIC (25.65 vs. 27.268), indicating a better model fit with 'drat' alone. The removal of 'disp' from the model does not substantially change the relationship between 'drat' and 'am', as the 'disp' coefficient was not significant in the previous model.

Choose one of the statistically significant predictors above.
Use `ggplot2` to plot `am` as a function of this predictor, and overlay a curve describing the logistic regression output when using *only* this predictor to predict `am` (i.e., the model from Part c above).

```{r}
library(ggplot2)
drat_range <- seq(min(mtcars$drat), max(mtcars$drat), by = 0.01)
logistic_curve <- data.frame(drat = drat_range)
logistic_curve$am <- predict(mtcars_logistic_drat, newdata = logistic_curve, type = "response")
ggplot(mtcars, aes(x = drat, y = am)) +
  geom_point() +
  geom_line(data = logistic_curve, aes(x = drat, y = am), color = "blue") +
  theme_minimal() +
  labs(title = "Logistic Regression: am vs drat",
       x = "drat",
       y = "am (automatic/manual)")
```


<br/>

## 3. Guided k-fold CV exercise <small>15pts</small>

In this exercise, we will guide you through an exercise where you are asked to use k-fold cross validation to evaluate the performance of several models.

For this exercise we will use the "Swiss Fertility and Socioeconomic Indicators (1888)" dataset from the `datasets` package, which is loaded below. (To view the help page, run `?datasets::swiss` in your console). We will be using `Fertility` as our response variable.

```{r}
swiss = datasets::swiss
```


### Part a) Understanding/visualizing data

Read the help page and briefly "introduce" this dataset. Specifically, explain where the data comes from, what variables it contains, and why should people care about the dataset.

Produce one or some visualizations of the data. Do your best here to try to use your plots to help your viewer best understand the structure and patterns of this dataset. Choose your plots carefully and briefly explain what each plot tells you about the data.

The Swiss Fertility dataset comes from the 1888 survey conducted in Switzerland. It includes fertility rates and several socioeconomic indicators for each of the 47 French-speaking provinces. The dataset contains the following variables:

Fertility: Number of live births per 1,000 women aged 15-49 per year
Agriculture: Percentage of males employed in agriculture
Examination: Percentage of draftees receiving the highest grade on a military examination
Education: Percentage of draftees with at least a primary education
Catholic: Percentage of the population that is Catholic
Infant Mortality: Infant mortality rate per 1,000 live births

This dataset helps understand the relationships between fertility rates and various factors during that period in Switzerland.

```{r}
pairs(swiss, col = "darkblue", pch = 16, lower.panel = NULL)

hist(swiss$Fertility, main = "Fertility", xlab = "Fertility Rate", col = "lightblue")
hist(swiss$Agriculture, main = "Agriculture", xlab = "Agriculture Employment Percentage", col = "lightblue")
hist(swiss$Examination, main = "Examination", xlab = "Examination Success Percentage", col = "lightblue")
hist(swiss$Education, main = "Education", xlab = "Primary Education Percentage", col = "lightblue")
hist(swiss$Catholic, main = "Catholic", xlab = "Catholic Population Percentage", col = "lightblue")
hist(swiss$Infant.Mortality, main = "Infant Mortality", xlab = "Infant Mortality Rate", col = "lightblue")
```

### Part b) Starting with basic lm

Compare a model with all predictors with no interactions with 2 other models of YOUR choice. Fit all 3 models, show their summary outputs, and briefly comment on which one you think might perform the best when used for future predictions and why.

```{r}
# Fit models
model1 = lm(Fertility ~ ., data = swiss)
model2 = lm(Fertility ~ Agriculture + Examination + Education + Catholic, data = swiss)
model3 = lm(Fertility ~ Examination + Education + Infant.Mortality, data = swiss)

summary(model1)
summary(model2)
summary(model3)
```
Model 1 is most likely to perform the best for future predictions due to its higher explanatory power and better overall fit.

### Part c) Estimating MSE using CV

Now, we are going to actually estimate the MSE of each model with K-fold cross validation. First we're going to set a seed and import the `caret` package (it should be already installed since it's a prerequisite for many other packages, but if it's not for some reason, you can install it with `install.packages("caret")`)

```{r}
set.seed(1)
library(caret)
```

Next, use the following chunk, which already has `method` set to `lm`, `data` set to the `swiss` data set, and validation method set to use 5-fold CV, to estimate the MSE of each of your models. All you need to do is add in a formula for your model and repeat for all 3 models you have.

```{r,error=T}
model1_cv = train(Fertility ~ ., method = "lm", data = swiss, trControl = trainControl(method = "cv", number = 5))
model2_cv = train(Fertility ~ Agriculture + Examination + Education + Catholic, method = "lm", data = swiss, trControl = trainControl(method = "cv", number = 5))
model3_cv = train(Fertility ~ Examination + Education + Infant.Mortality, method = "lm", data = swiss, trControl = trainControl(method = "cv", number = 5))

model1_cv$results
model2_cv$results
model3_cv$results
```

Once you have your models fitted, use `print( )` to show the summary statistics for each model. Report the RMSE for each model, which is the square root of the MSE. Which of these models performs the best? Which performed the worst? Do these results agree with your expectations?

Model 1 has the lowest RMSE and highest R-squared, which means that it performs the best among the three models. Model 3 performs the worst. The MAE values also follow the same pattern.These results agree with the expectations based on the previous analysis.

Bonus: repeat the above step, using `trControl = trainControl(method="repeatedcv", number=5, repeats=3)` which repeats each CV analysis 3times and averages out each run to get a more stable estimate of the MSE. Compare the results with the unrepeated MSE estimates. How do they compare?


<br/>

## 5. Variable selection with `Carseats` <small>10pts</small>

This question should be answered using the `Carseats` dataset from the `ISLR` package. If you do not have it, make sure to install it.

```{r}
library(ISLR)

Carseats = ISLR::Carseats

# you should read the help page by running ?Carseats
# we can also peek at the data frame before using it
str(Carseats)
head(Carseats)
```


### Part a) Visualizing/fitting

First, make some visualizations of the dataset to help set the stage for the rest of the analysis. Try to pick plots to show that are interesting informative.

```{r}
pairs(Carseats, col = "lightblue", pch = 16, lower.panel = NULL)

ggplot(Carseats, aes(x = ShelveLoc, y = Sales)) + geom_boxplot() + labs(title = "Sales vs ShelveLoc")
ggplot(Carseats, aes(x = CompPrice, y = Sales)) + geom_point() + labs(title = "Sales vs CompPrice")
ggplot(Carseats, aes(x = Income, y = Sales)) + geom_point() + labs(title = "Sales vs Income")
```

Using some variable selection method (stepwise, LASSO, ridge, or just manually comparing a preselected of models using their MSEs), choose a set of predictors to use to predict `Sales`. Try to find the best model that you can that explains the data well and doesn't have useless predictors. Explain the choices you made and show the final model.

```{r}
full_model = lm(Sales ~ ., data = Carseats)
step_model = step(full_model, direction = "both", trace = 0)
summary(step_model)
```
I chose Sales as a predictor because it does a good job at determining other variables related to carseats like price and income.

### Part b) Interpreting/assessing model

According to your chosen model, Which predictors appear to be the most important or significant in predicting sales? Provide an interpretation of each coefficient in your model. Be careful: some of the variables in the model are qualitative!

```{r}
coef(summary(step_model))
```
All predictors are statistically significant. The most important predictors are ShelveLocGood, Price, and CompPrice, based on their t-values. Good shelving locations increase sales, higher prices decrease sales, and higher competitor prices increase sales.

Estimate the out of sample MSE of your model and check any assumptions you made during your model fitting process. Discuss any potential model violations. How satisfied are you with your final model?

```{r}
cv_model = train(Sales ~ ., method = "lm", data = Carseats, trControl = trainControl(method = "cv", number = 5))
cv = cv_model$results$RMSE
sqrt(cv)
```
To evaluate the model, check linear regression assumptions using plots and tests. If assumptions are met and cross-validation RMSE is low, you can be more confident in the model's performance.
